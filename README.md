# Run Llama 3.2 1B Instruct GGUF locally

This repository provides a straightforward example demonstrating how to run the Meta Llama 3.2 model locally in your computer using the package llama-cpp-python
